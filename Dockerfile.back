# syntax=docker/dockerfile:1-labs
FROM python:3.12-alpine
WORKDIR /usr/local/app

# Build backend & ml dependencies
RUN pip install poetry==2.0.1

ENV POETRY_NO_INTERACTION=1 \
    POETRY_VIRTUALENVS_IN_PROJECT=1 \
    POETRY_VIRTUALENVS_CREATE=1 \
    POETRY_CACHE_DIR=/tmp/poetry_cache

RUN apk add --no-cache gdal-dev geos-dev proj-dev gcc g++ libc-dev
RUN mkdir ./backend
COPY backend/pyproject.toml backend/poetry.lock ./backend
RUN poetry -P backend/ install --without dev --no-root && rm -rf $POETRY_CACHE_DIR

# Train the model
COPY geodata geodata/

COPY ml ml/
RUN poetry -P backend/ run python ml/quick_predict.py --output backend/crime_model_simple.pkl

COPY backend backend/

WORKDIR /usr/local/app/backend
# Generate a secret key
RUN python >> config.py <<EOF
import os
print('SECRET_KEY="%x"' % int.from_bytes(os.urandom(32)))
EOF
EXPOSE 5000:5000
ENV ENVIRONMENT="PRODUCTION"
CMD ["poetry", "run", "waitress-serve", "--port", "5000", "--call", "app:create_app"]
